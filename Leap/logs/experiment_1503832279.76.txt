Data variables: 
	 train_paths: ['Leap_Data\\Legit_Data\\Participant 14\\Leap', 'Leap_Data\\Legit_Data\\Participant 15\\Leap', 'Leap_Data\\Legit_Data\\Participant 16\\Leap', 'Leap_Data\\Legit_Data\\Participant 17\\Leap', 'Leap_Data\\Legit_Data\\Participant 18\\Leap', 'Leap_Data\\Legit_Data\\Participant 19\\Leap', 'Leap_Data\\Legit_Data\\Participant 20\\Leap'], 
	 test_paths: ['Leap_Data\\Legit_Data\\Participant 12\\Leap'], 
	 use_auto_split: False, 
	 frames_per_gesture: 2, 
	 separate_frames: True, 
	 feature_set_type: all
svm_params: {'kernel': ['poly', 'linear', 'rbf'], 'C': [0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384], 'decision_function_shape': ['ovo', 'ovr'], 'degree': [0, 1, 2, 3, 4], 'gamma': [3.0517578125e-05, 6.103515625e-05, 0.0001220703125, 0.000244140625, 0.00048828125, 0.0009765625, 0.001953125, 0.00390625, 0.0078125, 0.015625, 0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4]}, 
 knn_params: {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree'], 'p': [1, 2, 3, 4, 5, 6, 7, 8, 9]}, 
 mlp_params: {'solver': ['lbfgs', 'sgd', 'adam'], 'activation': ('identity', 'logistic', 'tanh', 'relu'), 'hidden_layer_sizes': [(26,), (31,), (36,), (41,), (46,), (51,), (56,), (61,), (66,), (71,), (76,), (81,), (86,), (91,), (96,), (101,), (106,), (111,), (116,), (121,), (126,), (131,), (136,), (141,), (146,), (151,), (156,), (161,), (166,), (171,), (176,), (181,), (186,), (191,), (196,)], 'alpha': [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]}
normalizing
kNN chosen features: {'p': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'n_neighbors': 38}
CLASSIFIER: kNN 0.475
             precision    recall  f1-score   support

          a       0.40      0.64      0.49        22
          b       0.55      0.60      0.57        20
          c       0.91      0.91      0.91        22
          d       0.11      0.22      0.15        18
          e       0.00      0.00      0.00        18
          f       0.91      1.00      0.95        20
          g       0.79      0.86      0.83        22
          h       0.63      0.77      0.69        22
          i       0.41      0.65      0.50        20
          j       1.00      0.22      0.36        18
          k       0.20      0.22      0.21        18
          l       0.87      0.59      0.70        22
          m       0.00      0.00      0.00        20
          n       0.67      0.20      0.31        20
          o       0.89      0.73      0.80        22
          p       0.50      0.10      0.17        20
          q       0.60      1.00      0.75        18
          r       0.17      0.14      0.15        22
          s       0.26      0.60      0.36        20
          t       0.50      0.60      0.55        20
          u       0.19      0.15      0.17        20
          v       0.60      0.33      0.43        18
          w       0.46      0.27      0.34        22
          x       0.10      0.05      0.07        20
          y       1.00      1.00      1.00        20
          z       0.25      0.25      0.25        16

avg / total       0.51      0.47      0.46       520

[[14  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0
   0  0]
 [ 0 12  0  0  2  2  0  0  0  0  1  2  0  0  0  0  0  0  0  1  0  0  0  0
   0  0]
 [ 0  0 20  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  4  2  0  0  0  0  0  2  0  0  0  0  0  0  0 10  0  0  0  0  0
   0  0]
 [ 0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  4  6  0  0  0  0  0
   0  2]
 [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0 19  2  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  5 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  1  0  0  3  0  0  0 13  0  0  0  0  0  0  0  0  0  2  0  0  0  1  0
   0  0]
 [ 0  0  0  0  0  0  0  0 14  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 2  0  0  0  0  0  0  0  2  0  4  0  0  0  2  0  0  2  0  4  0  0  2  0
   0  0]
 [ 9  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 2  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  2  0  0  2
   0  0]
 [ 4  0  0  0  2  0  0  0  0  0  0  0  4  4  0  0  0  0  4  2  0  0  0  0
   0  0]
 [ 0  0  0  4  0  0  0  0  0  0  0  0  1  0 16  0  0  0  1  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  2 12  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0
   0  0]
 [ 0  2  0  8  2  0  0  0  0  0  1  0  0  0  0  0  0  3  2  0  2  0  0  2
   0  0]
 [ 0  0  0  0  2  0  0  0  0  0  0  0  2  0  0  0  0  2 12  2  0  0  0  0
   0  0]
 [ 4  0  0  0  2  0  0  0  0  0  0  0  0  2  0  0  0  0  0 12  0  0  0  0
   0  0]
 [ 0  3  0  4  0  0  0  0  2  0  3  0  3  0  0  0  0  1  0  1  3  0  0  0
   0  0]
 [ 0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  4  6  2  1
   0  0]
 [ 0  0  0  0  0  0  0  0  1  0  2  0  0  0  0  0  0  2  0  0  5  4  6  0
   0  2]
 [ 0  0  0  0  0  0  0  0  0  0  2  0  4  0  0  2  0  1  0  0  0  0  2  1
   0  8]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  20  0]
 [ 0  0  0  2  0  0  0  0  0  0  4  0  0  0  0  0  0  2  0  0  0  0  0  4
   0  4]]
MLP chosen features: {'hidden_layer_sizes': (161,), 'learning_rate': 'adaptive', 'solver': 'adam', 'alpha': 1, 'activation': 'tanh', 'learning_rate_init': 0.001}
CLASSIFIER: MLP 0.496153846154
             precision    recall  f1-score   support

          a       0.60      0.41      0.49        22
          b       0.42      0.40      0.41        20
          c       1.00      0.91      0.95        22
          d       0.00      0.00      0.00        18
          e       0.17      0.11      0.13        18
          f       0.86      0.90      0.88        20
          g       0.72      0.82      0.77        22
          h       0.60      0.68      0.64        22
          i       0.54      0.70      0.61        20
          j       0.89      0.89      0.89        18
          k       0.21      0.28      0.24        18
          l       0.82      0.82      0.82        22
          m       0.25      0.10      0.14        20
          n       0.50      0.30      0.37        20
          o       0.87      0.91      0.89        22
          p       1.00      0.10      0.18        20
          q       0.60      1.00      0.75        18
          r       0.13      0.18      0.15        22
          s       0.29      0.60      0.39        20
          t       0.55      0.80      0.65        20
          u       0.12      0.10      0.11        20
          v       0.32      0.33      0.32        18
          w       0.15      0.09      0.11        22
          x       0.19      0.15      0.17        20
          y       1.00      1.00      1.00        20
          z       0.14      0.12      0.13        16

avg / total       0.51      0.50      0.48       520

[[ 9  2  0  0  0  0  0  0  2  2  2  0  0  0  0  0  0  0  0  5  0  0  0  0
   0  0]
 [ 0  8  0  0  0  1  0  0  6  0  1  0  0  0  0  0  0  0  0  0  0  2  2  0
   0  0]
 [ 0  0 20  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  2  0  0  0  0  0  2  0  2  4  1  0  0  0  6  0  0  0  0  1
   0  0]
 [ 0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  4  6  0  0  0  0  4
   0  2]
 [ 0  2  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0 18  2  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  7 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  4  0  0  0 14  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  2  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  2  0  0  0  0  0  5  2  0  0  0  0  0  0  0  6  0  0  3  0
   0  0]
 [ 4  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  2  0  0  0  0  0  0  0  0  2  2  0  0  0  0 10  2  2  0  0  0
   0  0]
 [ 2  0  0  0  0  0  0  0  0  0  2  0  2  6  0  0  0  0  6  0  2  0  0  0
   0  0]
 [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  2 12  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0
   0  0]
 [ 0  2  0  6  0  0  0  0  0  0  4  0  0  0  0  0  0  4  0  0  0  2  2  0
   0  2]
 [ 0  1  0  0  2  0  0  0  0  0  0  0  2  0  0  0  0  2 12  0  0  1  0  0
   0  0]
 [ 0  2  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0
   0  0]
 [ 0  0  0  2  0  0  0  0  0  0  2  0  0  0  0  0  0 12  0  0  2  2  0  0
   0  0]
 [ 0  0  0  6  0  0  0  0  0  0  2  0  0  0  0  0  0  2  0  0  0  6  2  0
   0  0]
 [ 0  2  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  2  0  0  6  4  2  2
   0  2]
 [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  2  0  0  3  0  0  2  0  2  3
   0  6]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  20  0]
 [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  2  0  0  2  2  0  6
   0  2]]
SVM chosen features: {'kernel': 'rbf', 'C': 64, 'decision_function_shape': 'ovr', 'degree': 1, 'gamma': 3.0517578125e-05}
CLASSIFIER: SVM 0.496153846154
             precision    recall  f1-score   support

          a       0.58      0.64      0.61        22
          b       0.48      0.60      0.53        20
          c       0.96      1.00      0.98        22
          d       0.10      0.11      0.11        18
          e       0.00      0.00      0.00        18
          f       0.83      1.00      0.91        20
          g       0.55      0.82      0.65        22
          h       0.47      0.32      0.38        22
          i       0.41      0.65      0.50        20
          j       0.67      0.56      0.61        18
          k       0.29      0.44      0.35        18
          l       0.83      0.91      0.87        22
          m       0.30      0.15      0.20        20
          n       0.50      0.30      0.37        20
          o       0.77      0.91      0.83        22
          p       1.00      0.10      0.18        20
          q       0.60      1.00      0.75        18
          r       0.32      0.32      0.32        22
          s       0.19      0.40      0.26        20
          t       0.60      0.60      0.60        20
          u       0.15      0.20      0.17        20
          v       0.00      0.00      0.00        18
          w       0.67      0.18      0.29        22
          x       0.22      0.20      0.21        20
          y       1.00      1.00      1.00        20
          z       0.33      0.25      0.29        16

avg / total       0.50      0.50      0.47       520

[[14  0  1  0  0  0  0  0  2  1  4  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0 12  0  0  1  2  0  0  3  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0
   0  0]
 [ 0  0 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  2  2  0  0  0  0  0  0  0  2  0  0  0  0  2  8  2  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  8  0  0  0  0  6
   0  0]
 [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0 18  2  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0 15  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  3  0  0  0  0  0  0 13  2  0  0  0  0  0  0  0  0  2  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  2  0  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  2  0  0  0  0  0  8  2  0  0  0  0  0  0  0  4  0  0  2  0
   0  0]
 [ 2  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  1  1  0  0  0  2  0  0  0  3  2  0  0  0  0 11  0  0  0  0  0
   0  0]
 [ 4  0  0  0  0  0  0  0  0  0  2  0  1  6  0  0  0  0  5  0  2  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0 20  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  2 12  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0
   0  0]
 [ 0  2  0  6  0  0  0  0  0  0  1  0  0  0  0  0  0  7  0  0  2  0  0  0
   0  4]
 [ 0  2  0  0  2  0  0  0  0  0  1  0  2  2  0  0  0  1  8  0  0  0  0  2
   0  0]
 [ 4  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0 12  0  0  0  0
   0  0]
 [ 0  2  0  4  0  0  0  0  4  0  2  0  0  0  0  0  0  4  0  0  4  0  0  0
   0  0]
 [ 0  0  0  7  0  0  0  0  0  0  0  0  0  0  2  0  0  2  0  0  5  0  0  2
   0  0]
 [ 0  2  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  2  0  0 10  2  4  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  2  2  0  0  2  4  0  0  0  0  0  2  0  0  4
   0  4]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  20  0]
 [ 0  2  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  2  0  0  4
   0  4]]
CLASSIFIER: voting 0.525
             precision    recall  f1-score   support

          a       0.52      0.50      0.51        22
          b       0.48      0.60      0.53        20
          c       0.91      0.91      0.91        22
          d       0.09      0.11      0.10        18
          e       0.14      0.11      0.12        18
          f       0.91      1.00      0.95        20
          g       0.78      0.82      0.80        22
          h       0.63      0.77      0.69        22
          i       0.54      0.70      0.61        20
          j       0.88      0.78      0.82        18
          k       0.35      0.44      0.39        18
          l       0.90      0.82      0.86        22
          m       0.00      0.00      0.00        20
          n       0.67      0.40      0.50        20
          o       0.94      0.73      0.82        22
          p       0.50      0.10      0.17        20
          q       0.60      1.00      0.75        18
          r       0.36      0.23      0.28        22
          s       0.27      0.60      0.37        20
          t       0.45      0.70      0.55        20
          u       0.12      0.10      0.11        20
          v       0.44      0.44      0.44        18
          w       0.44      0.18      0.26        22
          x       0.20      0.10      0.13        20
          y       1.00      1.00      1.00        20
          z       0.27      0.38      0.32        16

avg / total       0.52      0.53      0.51       520

[[11  2  2  0  0  0  0  0  0  2  2  0  0  0  0  0  0  0  0  3  0  0  0  0
   0  0]
 [ 0 12  0  0  2  0  0  0  4  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0
   0  0]
 [ 0  0 20  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  2  2  0  0  0  0  0  2  0  0  0  0  0  0  0 10  0  0  0  0  0
   0  2]
 [ 0  0  0  2  2  0  0  0  0  0  0  0  0  0  0  0  0  4  6  0  0  0  0  2
   0  2]
 [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0 18  2  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  5 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  2  0  0  2  0  0  0 14  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  2  0  0  2 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  2  0  0  0  0  0  8  0  0  0  0  0  0  0  0  6  0  0  2  0
   0  0]
 [ 4  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  2  0  0  0  0  0  0  0  0  0  2  0  0  0  0 10  2  2  0  0  2
   0  0]
 [ 4  0  0  0  0  0  0  0  0  0  0  0  2  8  0  0  0  0  4  2  0  0  0  0
   0  0]
 [ 0  0  0  2  0  0  0  0  0  0  0  0  4  0 16  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  2 12  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0
   0  0]
 [ 0  3  0  6  0  0  0  0  0  0  2  0  0  0  0  0  0  5  0  0  0  2  0  0
   0  4]
 [ 0  0  0  0  4  0  0  0  0  0  0  0  2  0  0  0  0  2 12  0  0  0  0  0
   0  0]
 [ 2  2  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0 14  0  0  0  0
   0  0]
 [ 0  2  0  2  0  0  0  0  6  0  4  0  0  0  0  0  0  0  0  2  2  2  0  0
   0  0]
 [ 0  0  0  6  0  0  0  0  0  0  0  0  0  0  1  0  0  2  0  0  0  8  1  0
   0  0]
 [ 0  2  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  8  4  4  0
   0  2]
 [ 0  0  0  0  0  0  0  0  0  0  2  0  4  0  0  2  0  0  0  0  2  0  2  2
   0  6]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  20  0]
 [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  2  2  0  4
   0  6]]
