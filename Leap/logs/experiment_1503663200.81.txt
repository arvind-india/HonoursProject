Data variables: 
	 train_paths: ['Leap_Data\\DataGath1', 'Leap_Data\\DataGath3', 'Leap_Data\\Participant 0'], 
	 test_paths: ['Leap_Data\\DataGath2'], 
	 use_auto_split: False, 
	 frames_per_gesture: 2, 
	 separate_frames: False, 
	 feature_set_type: all
svm_params: [{'kernel': ['rbf'], 'C': [0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384], 'decision_function_shape': ['ovo', 'ovr'], 'gamma': [3.0517578125e-05, 6.103515625e-05, 0.0001220703125, 0.000244140625, 0.00048828125, 0.0009765625, 0.001953125, 0.00390625, 0.0078125, 0.015625, 0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4]}], 
 knn_params: [{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree'], 'p': [1, 2, 3, 4, 5, 6, 7, 8, 9]}], 
 mlp_params: {'solver': ['lbfgs', 'sgd', 'adam'], 'activation': ('identity', 'logistic', 'tanh', 'relu'), 'hidden_layer_sizes': [(26,), (31,), (36,), (41,), (46,), (51,), (56,), (61,), (66,), (71,), (76,), (81,), (86,), (91,), (96,), (101,), (106,), (111,), (116,), (121,), (126,), (131,), (136,), (141,), (146,), (151,), (156,), (161,), (166,), (171,), (176,), (181,), (186,), (191,), (196,)], 'alpha': [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]}
normalize: True
SelectKBest(k=200, score_func=<function f_classif at 0x0000000017489E48>)
number of features: 200
SVM chosen features: {'kernel': 'rbf', 'C': 16, 'decision_function_shape': 'ovo', 'gamma': 0.00390625}
CLASSIFIER: SVM 0.511627906977
             precision    recall  f1-score   support

          a       0.67      0.80      0.73         5
          b       0.57      0.80      0.67         5
          c       0.67      0.40      0.50         5
          d       1.00      0.40      0.57         5
          e       0.50      0.40      0.44         5
          f       0.75      0.60      0.67         5
          g       1.00      0.20      0.33         5
          h       0.45      1.00      0.62         5
          i       0.43      0.60      0.50         5
          j       0.33      0.20      0.25         5
          k       0.60      0.60      0.60         5
          l       1.00      1.00      1.00         5
          m       0.00      0.00      0.00         5
          n       0.00      0.00      0.00         5
          o       0.50      0.80      0.62         5
          p       1.00      0.60      0.75         5
          q       1.00      1.00      1.00         5
          r       0.14      0.20      0.17         5
          s       0.40      0.40      0.40         5
          t       0.43      0.60      0.50         5
          u       0.00      0.00      0.00         5
          v       0.17      0.25      0.20         4
          w       1.00      0.40      0.57         5
          x       0.67      0.40      0.50         5
          y       1.00      1.00      1.00         5
          z       1.00      0.60      0.75         5

avg / total       0.59      0.51      0.52       129

[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]
 [0 4 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 2 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 3 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 0 1 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 4 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [1 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 2 0 0 0 0 0 0]
 [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0]
 [0 0 1 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 0 0 0 0 0]
 [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0]
 [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 3 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 1 0 0]
 [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 2 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0]
 [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 3]]
