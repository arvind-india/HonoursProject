Data variables: 
	 train_paths: ['Leap_Data\\Legit_Data\\Participant 12\\Leap', 'Leap_Data\\Legit_Data\\Participant 13\\Leap', 'Leap_Data\\Legit_Data\\Participant 15\\Leap', 'Leap_Data\\Legit_Data\\Participant 16\\Leap', 'Leap_Data\\Legit_Data\\Participant 17\\Leap', 'Leap_Data\\Legit_Data\\Participant 18\\Leap', 'Leap_Data\\Legit_Data\\Participant 19\\Leap', 'Leap_Data\\Legit_Data\\Participant 20\\Leap', 'Leap_Data\\Legit_Data\\Participant 21\\Leap', 'Leap_Data\\Legit_Data\\Participant 22\\Leap', 'Leap_Data\\Legit_Data\\Participant 23\\Leap'], 
	 test_paths: ['Leap_Data\\Legit_Data\\Participant 14\\Leap'], 
	 use_auto_split: False, 
	 frames_per_gesture: 2, 
	 separate_frames: False, 
	 feature_set_type: all 
	 average: False
scaling
SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
           verbose=0, warm_start=False),
        prefit=False, threshold=0.002)
number of features: 193
svm_params: {'kernel': ['poly', 'linear', 'rbf'], 'C': [0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384], 'decision_function_shape': ['ovo', 'ovr'], 'degree': [0, 1, 2, 3, 4], 'gamma': [3.0517578125e-05, 6.103515625e-05, 0.0001220703125, 0.000244140625, 0.00048828125, 0.0009765625, 0.001953125, 0.00390625, 0.0078125, 0.015625, 0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4]}, 
 knn_params: {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree'], 'p': [1, 2, 3, 4, 5, 6, 7, 8, 9]}, 
 mlp_params: {'solver': ['lbfgs', 'sgd', 'adam'], 'activation': ('identity', 'logistic', 'tanh', 'relu'), 'hidden_layer_sizes': [(26,), (31,), (36,), (41,), (46,), (51,), (56,), (61,), (66,), (71,), (76,), (81,), (86,), (91,), (96,), (101,), (106,), (111,), (116,), (121,), (126,), (131,), (136,), (141,), (146,), (151,), (156,), (161,), (166,), (171,), (176,), (181,), (186,), (191,)], 'alpha': [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]}
kNN chosen features: {'p': 1, 'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 10}
CLASSIFIER: kNN 0.423076923077
             precision    recall  f1-score   support

          a       0.40      0.44      0.42         9
          b       0.38      0.30      0.33        10
          c       0.90      0.82      0.86        11
          d       0.00      0.00      0.00        11
          e       0.10      0.10      0.10        10
          f       0.50      0.90      0.64        10
          g       0.44      0.44      0.44         9
          h       0.55      0.60      0.57        10
          i       0.40      0.36      0.38        11
          j       0.50      0.36      0.42        11
          k       0.50      0.60      0.55        10
          l       0.64      0.78      0.70         9
          m       0.20      0.10      0.13        10
          n       0.67      0.20      0.31        10
          o       0.32      0.80      0.46        10
          p       1.00      0.70      0.82        10
          q       0.69      1.00      0.82         9
          r       0.23      0.33      0.27         9
          s       0.00      0.00      0.00        11
          t       0.50      0.30      0.37        10
          u       0.21      0.30      0.25        10
          v       0.31      0.56      0.40         9
          w       0.50      0.36      0.42        11
          x       0.12      0.10      0.11        10
          y       1.00      0.70      0.82        10
          z       0.00      0.00      0.00        10

avg / total       0.42      0.42      0.40       260

[[4 0 0 0 0 1 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 3 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 1 1 1 1 0 0]
 [0 0 9 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 3 4 0 2 0 0]
 [0 0 0 0 1 2 0 0 1 0 1 0 0 0 2 0 0 0 3 0 0 0 0 0 0 0]
 [0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]
 [0 0 1 0 0 0 4 3 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 4 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 2 0 1 0 0 0 0 4 3 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]
 [0 0 0 0 1 1 0 0 3 4 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 2 0 0 0 0 6 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 1 0 0 0 7 0 0 0 0 0 0 0 1 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0 0 0 1 0 6 0 0 0 0 0 1 0 0 0 0 0]
 [1 0 0 1 0 0 0 0 2 0 0 0 1 2 0 0 0 0 2 0 0 0 0 0 0 1]
 [0 0 0 1 0 0 0 0 0 0 0 0 0 1 8 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 3 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0]
 [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 3 0 0 2 2 0 0 0 0]
 [1 0 0 0 2 1 0 0 0 0 0 0 1 0 3 0 0 0 0 0 1 0 0 1 0 1]
 [3 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 1 3 0 0 0 0 0 0]
 [0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 3 1 1 1 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 5 1 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 1 0 0 0 0 4 2 0 0]
 [0 0 0 1 2 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0]
 [0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 7 0]
 [1 0 0 3 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 0 1 1 0 0 0 0]]
MLP chosen features: {'hidden_layer_sizes': (191,), 'learning_rate': 'adaptive', 'solver': 'adam', 'alpha': 0.1, 'activation': 'tanh', 'learning_rate_init': 0.0001}
CLASSIFIER: MLP 0.476923076923
             precision    recall  f1-score   support

          a       0.42      0.56      0.48         9
          b       0.50      0.50      0.50        10
          c       1.00      0.82      0.90        11
          d       0.33      0.09      0.14        11
          e       0.00      0.00      0.00        10
          f       0.60      0.90      0.72        10
          g       0.40      0.44      0.42         9
          h       0.40      0.60      0.48        10
          i       0.56      0.45      0.50        11
          j       0.33      0.18      0.24        11
          k       0.50      0.50      0.50        10
          l       0.64      0.78      0.70         9
          m       0.33      0.40      0.36        10
          n       0.71      0.50      0.59        10
          o       0.29      0.40      0.33        10
          p       0.91      1.00      0.95        10
          q       1.00      0.89      0.94         9
          r       0.33      0.67      0.44         9
          s       0.00      0.00      0.00        11
          t       0.42      0.50      0.45        10
          u       0.38      0.30      0.33        10
          v       0.42      0.56      0.48         9
          w       0.40      0.36      0.38        11
          x       0.43      0.30      0.35        10
          y       1.00      0.70      0.82        10
          z       0.33      0.20      0.25        10

avg / total       0.48      0.48      0.47       260

[[ 5  0  0  0  0  1  0  1  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  5  0  0  1  0  0  0  0  1  1  0  1  0  0  0  0  1  0  0  0  0  0  0
   0  0]
 [ 0  0  9  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  1  2  0  0  0  0  0  0  0  0  0  1  0  0  3  0  0  1  1  0  1
   0  1]
 [ 1  2  0  0  0  1  0  0  0  0  1  0  0  0  1  0  0  0  2  0  0  1  0  1
   0  0]
 [ 0  0  0  0  0  9  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  4  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  4  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  1  0  0  0  0  0  0  5  2  0  0  0  0  0  0  0  0  1  1  1  0  0  0
   0  0]
 [ 0  0  0  0  1  2  0  0  3  2  0  0  0  0  1  0  0  0  0  0  0  0  1  0
   0  1]
 [ 0  0  0  0  0  0  0  0  0  0  5  1  0  0  0  0  0  1  0  3  0  0  0  0
   0  0]
 [ 1  0  0  0  0  0  0  1  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  1  0  1  0  0  0  0  0  4  0  4  0  0  0  0  0  0  0  0  0
   0  0]
 [ 1  0  0  0  0  0  0  0  1  0  0  0  1  5  0  0  0  0  1  0  0  0  0  0
   0  1]
 [ 0  0  0  0  1  0  0  0  0  0  0  0  2  1  4  0  0  0  1  0  0  0  0  0
   0  1]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  8  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0  1  0  1  0
   0  0]
 [ 1  0  0  0  4  0  0  0  0  0  1  0  2  0  2  0  0  1  0  0  0  0  0  0
   0  0]
 [ 3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  5  0  0  0  0
   0  0]
 [ 0  1  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  3  1  1  1
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  1  5  1  0
   0  0]
 [ 0  0  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  1  0  2  0  1  4  1
   0  0]
 [ 0  0  0  1  0  0  0  0  0  0  0  0  1  0  1  0  0  1  0  0  0  2  1  3
   0  0]
 [ 0  0  0  0  0  1  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0
   7  0]
 [ 0  0  0  0  1  0  0  0  0  0  0  0  1  1  0  0  0  2  0  0  1  1  1  0
   0  2]]
SVM chosen features: {'kernel': 'rbf', 'C': 16, 'decision_function_shape': 'ovo', 'degree': 2, 'gamma': 0.00048828125}
CLASSIFIER: SVM 0.476923076923
             precision    recall  f1-score   support

          a       0.31      0.44      0.36         9
          b       0.50      0.50      0.50        10
          c       1.00      0.91      0.95        11
          d       0.20      0.18      0.19        11
          e       0.00      0.00      0.00        10
          f       0.64      0.90      0.75        10
          g       0.55      0.67      0.60         9
          h       0.64      0.90      0.75        10
          i       0.60      0.55      0.57        11
          j       0.50      0.18      0.27        11
          k       0.60      0.60      0.60        10
          l       0.78      0.78      0.78         9
          m       0.30      0.30      0.30        10
          n       0.57      0.40      0.47        10
          o       0.29      0.40      0.33        10
          p       1.00      1.00      1.00        10
          q       1.00      1.00      1.00         9
          r       0.27      0.67      0.39         9
          s       0.14      0.09      0.11        11
          t       0.22      0.20      0.21        10
          u       0.27      0.30      0.29        10
          v       0.44      0.44      0.44         9
          w       0.36      0.36      0.36        11
          x       0.00      0.00      0.00        10
          y       0.88      0.70      0.78        10
          z       0.25      0.10      0.14        10

avg / total       0.47      0.48      0.46       260

[[ 4  0  0  0  0  0  2  1  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0
   0  0]
 [ 0  5  0  1  1  0  0  0  0  1  0  0  0  0  0  0  0  2  0  0  0  0  0  0
   0  0]
 [ 0  0 10  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  2  1  0  0  0  0  0  0  0  0  0  1  0  0  4  1  0  1  0  0  1
   0  0]
 [ 1  2  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  2  0  1  1  0  1
   0  0]
 [ 0  0  0  0  0  9  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  6  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  1  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  1  0  0  0  0  0  0  6  1  0  0  0  0  0  0  0  0  1  0  1  0  1  0
   0  0]
 [ 0  0  0  0  1  1  0  0  4  2  0  0  0  0  1  0  0  0  0  0  0  0  2  0
   0  0]
 [ 0  0  0  0  0  1  0  0  0  0  6  0  0  0  0  0  0  1  0  2  0  0  0  0
   0  0]
 [ 1  0  0  0  0  0  0  1  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  1  0  1  0  0  0  0  0  3  0  5  0  0  0  0  0  0  0  0  0
   0  0]
 [ 2  0  0  0  0  0  0  0  0  0  0  0  2  4  0  0  0  0  1  0  0  0  0  1
   0  0]
 [ 0  0  0  1  1  0  0  0  0  0  0  0  2  2  4  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0  1  0  1  0
   0  0]
 [ 1  0  0  2  3  0  0  0  0  0  1  0  1  0  2  0  0  0  1  0  0  0  0  0
   0  0]
 [ 4  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  0  0  0  0
   0  2]
 [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  3  1  1  1
   1  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  1  1  4  0  0
   0  0]
 [ 0  0  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  1  0  2  0  1  4  1
   0  0]
 [ 0  0  0  2  0  0  0  0  0  0  0  0  1  0  1  0  0  1  0  0  1  2  1  0
   0  1]
 [ 0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0
   7  0]
 [ 0  0  0  1  0  0  0  0  0  0  0  0  1  1  0  0  0  2  0  0  2  0  1  1
   0  1]]
CLASSIFIER: voting 0.488461538462
             precision    recall  f1-score   support

          a       0.50      0.56      0.53         9
          b       0.42      0.50      0.45        10
          c       0.90      0.82      0.86        11
          d       0.00      0.00      0.00        11
          e       0.00      0.00      0.00        10
          f       0.60      0.90      0.72        10
          g       0.57      0.44      0.50         9
          h       0.56      0.90      0.69        10
          i       0.50      0.55      0.52        11
          j       0.50      0.36      0.42        11
          k       0.55      0.60      0.57        10
          l       0.73      0.89      0.80         9
          m       0.29      0.20      0.24        10
          n       0.57      0.40      0.47        10
          o       0.26      0.60      0.36        10
          p       0.91      1.00      0.95        10
          q       0.89      0.89      0.89         9
          r       0.25      0.44      0.32         9
          s       0.20      0.09      0.13        11
          t       0.57      0.40      0.47        10
          u       0.23      0.30      0.26        10
          v       0.36      0.56      0.43         9
          w       0.57      0.36      0.44        11
          x       0.22      0.20      0.21        10
          y       1.00      0.70      0.82        10
          z       0.50      0.20      0.29        10

avg / total       0.48      0.49      0.47       260

[[ 5  0  0  0  0  1  0  1  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  5  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  2  0  1
   0  0]
 [ 0  0  9  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  2  0  0  3  2  0  2
   0  0]
 [ 0  2  0  0  0  1  0  0  1  0  1  0  0  0  3  0  0  0  2  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  9  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  1  0  0  0  4  3  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  1  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  2  0  0  0  0  0  0  6  2  0  0  0  0  0  0  0  0  0  0  1  0  0  0
   0  0]
 [ 0  0  0  0  0  1  0  0  4  4  0  0  0  0  2  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  1  0  0  0  2  0  0  0  0  6  0  0  0  0  0  0  1  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  1  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  1  0  1  0  0  0  0  0  2  0  6  0  0  0  0  0  0  0  0  0
   0  0]
 [ 1  0  0  0  0  0  0  0  1  0  0  0  1  4  0  0  0  0  2  0  0  0  0  0
   0  1]
 [ 0  0  0  1  0  0  0  0  0  0  0  0  1  2  6  0  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  8  0  0  0  0  0  0  0
   0  0]
 [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  1  2  1  0
   0  0]
 [ 1  0  0  0  3  0  0  0  0  0  1  0  1  0  3  0  0  1  1  0  0  0  0  0
   0  0]
 [ 3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  1
   0  1]
 [ 0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  2  0  0  3  1  1  1
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  2  5  0  0
   0  0]
 [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  1  0  2  0  0  4  2
   0  0]
 [ 0  0  0  1  0  0  0  0  0  0  0  0  1  0  2  0  0  1  0  0  1  1  1  2
   0  0]
 [ 0  0  0  0  0  1  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0
   7  0]
 [ 0  0  0  1  0  0  0  0  0  0  0  0  1  1  0  0  0  2  0  0  2  1  0  0
   0  2]]
